{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a014bd0a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Visualization\n",
    "### Foundations of Machine Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41849e9b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Introduction\n",
    "- The histogram or kernel density are our most common ways of visualizing data, and provide great intuition about **relative** likelihood of occurring: More height, more likely\n",
    "- Choosing the number of bins or the bandwidth can feel arbitrary, and doing it incorrectly can be misleading\n",
    "- Today we focus on more **robust** tools that summarize variables without being as sensitive to extreme values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e12c24",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Outline\n",
    "1. ECDF and Quantiles\n",
    "2. Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bcc910",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The ECDF and Quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d29b48",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Empirical Cumulative Distribution Function (ECDF)\n",
    "- The ECDF of a variable $X$ is:\n",
    "    1. Fix a value; let's call it $x$\n",
    "    2. Compute the proportion of obervations whose value falls below $x$: That's the value of the ECDF at $x$\n",
    "    3. Do this for all values of $x$ that occur in your data\n",
    "- This generates a graph that increases as you move from the left to the right, with a jump at every value in the dataset\n",
    "\n",
    "| Method | Usage |\n",
    "| :---: | :---:|\n",
    "| `df[var].plot.ecdf()` | Pandas ECDF |\n",
    "| `sns.ecdfplot(df[var])` | Seaborn ECDF |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6203a3ea",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Median\n",
    "- The **median** is a measure of central tendency, like the mean\n",
    "- It is the value $m$ for which (approximately) 50% of the population is above $m$ and 50% of the population is below $m$\n",
    "- It is more **robust** than the mean, because if we adjust very high or very low values, it typically won't change the median at all, but would often impact the value of the mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58155dac",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Quantiles\n",
    "- The concept of a Quantile generalizes the Median\n",
    "- Take the ECDF, and pick a number on the vertical axis, like .4\n",
    "- Trace that value to the graph\n",
    "- Now trace down from the graph to the horizontal axis\n",
    "- This value is the 40th percentile or .4 quantile: The value of $X$ for which 40% or a proportion .4 of the sample is below that value\n",
    "\n",
    "| Method | Usage |\n",
    "| :---: | :---:|\n",
    "| `np.quantile(X,q)` | Gives the $q$ quantile of $X$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe113ab5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 5-Number Summary\n",
    "- Since there are many quantiles to consider (one for each data point), we typically focus on a handful of key ones:\n",
    "    - The 0-quantile, the sample minimum\n",
    "    - The .25-quantile\n",
    "    - The .5-quantile, the sample median\n",
    "    - The .75-quantile\n",
    "    - The 1-quantile, the sample maximum\n",
    "- This is called a **five-number summary**\n",
    "\n",
    "| Method | Usage |\n",
    "| :---: | :---:|\n",
    "| `df['var'].describe()` | Summarizes the data |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6314bd99",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise\n",
    "- Plot the ECDF and compute a 5 number summary for a numeric variable of interest in your data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3955d53a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3d41c3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Extreme Behavior\n",
    "- Our models are often sensitive to **extreme values** or **outliers** \n",
    "- Our models are **robust** if changes to the higher-est and lower-est values do not significantly impact our estimates\n",
    "- The mean is not robust, but the median is\n",
    "- In many scenarios, identifying extreme values and handling them is an important part of the process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8422b9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Interquartile Range\n",
    "- The **interquartile range** or IQR is the range of values between the .25 and .75 quantiles\n",
    "- This contains 50% of the observations\n",
    "- If the IQR is relatively small, most of the data are in a tight window; if it is large, the data are relatively spread out\n",
    "- Like the median is a robust version of the mean, the IQR is a robust version of the variance: It quantifies how spread out the data are, but isn't sensitive to extreme values\n",
    "\n",
    "| Method | Usage |\n",
    "| :---: | :---:|\n",
    "| `iqr = np.quantile(df['var'], .75) - np.quantile(df['var'], .25) ` | Compute IQR |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2f8eff",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Boxplots\n",
    "- The histogram/density plot visualizes relative frequency and the ECDF visualizes absolute frequency\n",
    "- The **boxplot** visualizes the 5 number summary, median, and extreme values\n",
    "\n",
    "| Method | Usage |\n",
    "| :---: | :---:|\n",
    "| `df['var'].boxplot() ` | Pandas boxplot |\n",
    "| `sns.boxplot(df['var']) ` | Seaborn boxplot |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63037b0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Whiskers\n",
    "- Boxplots typically have two lines that extend from the top and bottom of the box, and then a \"scatterplot\" of points outside those lines. The **whiskers** extent to:\n",
    "    - The .75-quantile plus $1.5 \\times IQR$\n",
    "    - The .25-quantile minus $1.5 \\times IQR$\n",
    "- The points outside the whiskers are typically called **outliers**, but that word is squishy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becb8562",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "```python\n",
    "# Compute whiskers:\n",
    "q75 = np.nanquantile(df['var_outlier'], .75)\n",
    "q25 = np.nanquantile(df['var_outlier'], .25)\n",
    "iqr = q75 - q25\n",
    "upper_whisker = q75 + 1.5 * iqr\n",
    "lower_whisker = q25 - 1.5 * iqr\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de33061e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Outliers\n",
    "- The outliers are part of the data\n",
    "    - Hurricanes, earthquakes, stock market crashes, heart attacks are all extreme events --- and we care about them, very much\n",
    "    - But some observations might not be representative of the population of interest, like a Maserati or Ferrari in a dataset of used cars\n",
    "- We have three strategies that we use for handling a situation in which there are many outliers:\n",
    "    1. Drop the outliers\n",
    "    2. Winsorize: Round the values outside the whiskers to the values of the nearest whisker\n",
    "    3. Transform: Take a logarithm or inverse hyperbolic sine to \"squash\" the data into a smaller interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d215b336",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Handling Outliers\n",
    "- Suppose the variable is `var`\n",
    "- We can create an outlier dummy with:\n",
    "```python\n",
    "# Outlier dummy:\n",
    "df['var_is_outlier'] = ( (df['var'] < lower_whisker) |\n",
    "(df['var'] > upper_whisker) ).astype(int)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b3dc7d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- And to winsorize:\n",
    "```python\n",
    "df['var_winsorize'] = ( (df['var'] < lower_whisker) * lower_whisker \n",
    "+ (df['var'] > upper_whisker) * upper_whisker \n",
    "+ (df['var'] >= lower_whisker) * (df['var'] <= upper_whisker) * df['var'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e29a52",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Handling Outliers\n",
    "- If there's a handful of extreme values, dropping them is appropriate\n",
    "- Taking a log or archsinh transformation works best when the variable just has a very long tail\n",
    "- If there's a large number of extreme values, but they're not **that** far from the whiskers, then winsorizing is a good compromise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a798e3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Violin Plots\n",
    "- The violin plot smashes the boxplot and the kernel density plot together\n",
    "- This is nice if you want to see everything all at once\n",
    "\n",
    "| Method | Usage |\n",
    "| :---: | :---:|\n",
    "| `sns.violinplot( x=df['var'], inner='quart',fill=False) ` | Seaborn violin plot |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c20ea8d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise\n",
    "- Make a plot of a numeric variable of interest in your data\n",
    "- Detect outliers\n",
    "- Winsorize, drop, or transform?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
