{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b49504c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Wrangling\n",
    "### `! git clone https://github.com/ds4e/wrangling`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd04fd7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data Wrangling\n",
    "- Today, we just want to open the data and learn the basic steps of interacting with it\n",
    "- Before we can do even the most basic analysis, there's typically a lot of work to get the data in a state where it can be used\n",
    "- This kind of pre-analysis cleaning and management is called **Data Wrangling** or **Data Cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea7f96e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data Wrangling\n",
    "- According to a survey by CloudFlower and popularized by Forbes, about 82% of data scientists' time is spent on cleaning and organizing data:\n",
    "\n",
    "![Time use](./src/timespent.jpg)\n",
    "\n",
    "\"76% of data scientists view data preparation as the least enjoyable part of their work.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf6b869",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Files Containing Data\n",
    "- These are the most common file formats I am aware of, and what programs or languages created them:\n",
    "\n",
    "| File Format Extension | Likely Source |\n",
    "| :---: | :---:|\n",
    "|.csv | Any |\n",
    "|.Rda, .Rdata | R |\n",
    "|.dat | SAS |\n",
    "|.sav | SPSS |\n",
    "|.dta | Stata |\n",
    "|.mat | MATLAB |\n",
    "|.xls, .xlsx | Excel |\n",
    "|.json | JavaScript Object Notation|\n",
    "|.parquet | Apache parquet format|\n",
    "|.orc | Optimized Row Columnar, for big data |\n",
    "\n",
    "- Unless you have a good reason, .csv is probably the most accessible format for most people\n",
    "- More modern formats like parquet and orc save space by storing values in a clever way. If a column is just 0's and 1's with mostly 0's for example, they'll just track the indices where a 1 appears, rather than storing the whole column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c86e26",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Codebooks\n",
    "- Data come with documentation, which I am going to generically call a *codebook* or a *data dictionary*\n",
    "- It might be a formal codebook, or it might just be the survey itself that respondents filled out, or it might just be the html/javascript code that created the web page that captured the responses\n",
    "- It's easy to make mistakes without a codebook:\n",
    "    - `Employees` might be a `True/False` about whether the firm has any employees at all, or it might be the number of employees it employs, and so on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bcf2d8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Opening Data\n",
    "- In order to work with our data, we need software that handles dataframes. Python does not automatically do this.\n",
    "\n",
    "`import pandas as pd`\n",
    "\n",
    "- Open a notebook, and write \n",
    "\n",
    "\n",
    "| Method | Usage |\n",
    "| :---: | :---:|\n",
    "| `df = pd.read_csv(path)` | Open a generic .csv |\n",
    "| `df = pd.read_csv(<filename>, encoding = 'latin1')` | Warning about UTF-8 encoding |\n",
    "| `df = pd.read_csv(<filename>, sep='\\t')` | Tab-separated file, (or pipe `\\|`, etc.) |\n",
    "| `df = pd.read_parquet(<filename>,engine='fastparquet)` | Open parquet file; `pip install fastparquet` if necessary |\n",
    "\n",
    "- Load the `airbnb_NYC.csv` data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fa9124",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data \n",
    "- A data point or datum is the intersection of three things:\n",
    "    1. **Observation**: The person, place, or thing being considered\n",
    "    2. **Variable**: A **numeric** (price, age) or **categorical** (color, brand) representation of some aspect of the observation\n",
    "    3. **Value**: The **number** (for numeric) or **label** (for categorical) recorded\n",
    "- A collection of observations is typically represented in a **dataframe**: An $N$-observations by $L$-variables rectangular matrix of information\n",
    "- So we can have `car = (price, age, color, brand)`, or `patient = (blood_pressure, A1C, creatine_phosphokinase)`, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cc9541",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Summarizing the Data Frame\n",
    "\n",
    "- What are the basic features of the data frame?\n",
    "\n",
    "| Method | Usage |\n",
    "| :---: | :---:|\n",
    "| `df.shape` | Number of rows and columns |\n",
    "| `df.columns` | Names of the variables |\n",
    "| `df.dtypes` | Types of the variables |\n",
    "| `df.head(n)` | First $n$ rows |\n",
    "| `df.tail(n)` | Last $n$ rows |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991bc014",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Summarizing a Variable\n",
    "\n",
    "- Great, our data are loaded. Let's dig into these variables.\n",
    "- What are the basic features of a variable, `var` ?\n",
    "\n",
    "| Method | Usage |\n",
    "| :---: | :---:|\n",
    "| `df[var].unique()` | List of values it takes |\n",
    "| `df[var].value_counts()` | Counts of each value |\n",
    "| `df[var].plot.hist()`, `df[var].plot.kde()` | Histogram of values |\n",
    "| `df[var].describe()` | Statistical summary |\n",
    "\n",
    "- I personally like `skimpy` as the solution for getting a quick overview of all variables `skim(df)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e40442c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Missing Values\n",
    "- For a given observation and variable, if a value is not recorded, that value is **missing**\n",
    "- Pandas records these as `np.nan` or `None` internally \n",
    "\n",
    "| Method | Usage |\n",
    "| :---: | :---:|\n",
    "| `df['var_na'] = df[var].isna()` | Missing value indicator |\n",
    "\n",
    "- The fact that the value is missing is **information**. If data are systematically missing, we might be (very) worried. Some examples:\n",
    "    - Skip Patterns: Questions are only asked in a survey if previous questions are affirmative\n",
    "    - Selection Bias: Wages are not observed for people out of the labor force; people who make very high or very low wages might not be as inclined to search for work\n",
    "    - Bond: Bonds in VA are only recorded if they are strictly positive; no one is recorded as having a bond of 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede24c5b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Survivor Bias](./src/plane.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9e79a8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Cleaning a Numeric Variable\n",
    "\n",
    "- Many numeric variables are erroneously read in by Pandas as categorical\n",
    "- This typically happens because either the comma is retained in numbers like $1,000$, or $'s appear in the variable, or the missing values are recorded as text like `NA`\n",
    "\n",
    "| Method | Usage |\n",
    "| :---: | :---:|\n",
    "| 1. `df[var].str.replace(pattern,replace)` | Substitute `pattern` with `replace`, like `,` or `$` with ` `  |\n",
    "| 2. `pd.to_numeric(df[var],errors='coerce')` | Cast `var` to numeric, when possible, or replace with `np.nan`  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f753ed2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Imputation\n",
    "\n",
    "- So you have those `np.nan` values left in the data frame, what do you do with them?\n",
    "- It depends on the analytics you plan to do\n",
    "- But here's a reasonable for now\n",
    "\n",
    "| Method | Usage |\n",
    "| :---: | :---:|\n",
    "| 1. `df[var_na] = df[var].isna()` | Save a missing value dummy |\n",
    "| 2. `imputation_value = df[var].mean()` | Compute a value to replace missings (or median,e tc.) |\n",
    "| 3. `df['var_imp'] = df[var].fillna(imputation_value)` | Replace missings with `imputation_value` |\n",
    "\n",
    "Notice, we didn't get rid of the original variable, and we deliberately made a missing value dummy for later analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1edd057",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Replacing and Mapping \n",
    "- Sometimes, you just need to rewire the whole variable\n",
    "- First, make a dictionary\n",
    "\n",
    "\n",
    "\n",
    "| Method | Use |\n",
    "| :---: | :---:|\n",
    "| 1. `dict = {old_value:new_value,...}` | Create a dictionary of replacement values |\n",
    "| 2. `df[var_map] = df[var].map(dict)` | Pass the dict to `.map()` |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb7eeff",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Logical Operators\n",
    "- Often, we want to check a logical condition for every observation\n",
    "- These are some of the most commonly used logical operators:\n",
    "\n",
    "| Operator | Meaning | Example |\n",
    "| :---: | :---:| :---:|\n",
    "| `and` | and | |\n",
    "|`or` | or | |\n",
    "|$==$, $!=$ | equivalence, inequivalence | |\n",
    "|`<=`,`<` | less-than-equal-to, less-than | |\n",
    "| `in`, `not in`| set membership, set non-membership | |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cdb641",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Row and Column Filtering\n",
    "- We'd like to grab rows of interest and columns of interest, for many reasons.\n",
    "- This is accomplished through the **locator function**, `.loc`\n",
    "\n",
    "- Imagine we have \n",
    "    1. A logical/Boolean condition, `logical_conditional`, `like age>50` or `price<10_000`\n",
    "    2. A list of variables of interest, `var_list = [var_1, var_2, ... ]`\n",
    "\n",
    "| Method | Use |\n",
    "| :---: | :---:|\n",
    "| `df.loc[logical_conditional,:]` | Write the dataframe to `path` |\n",
    "| `df.loc[:,var_list]` | Write the dataframe to `path` |\n",
    "| `df.loc[logical_conditional,var_list]` | Both! |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f72b4a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Saving the Data\n",
    "- You've done all this work, how do we save it?\n",
    "\n",
    "| Method | Use |\n",
    "| :---: | :---:|\n",
    "| `df.to_csv(path,index=False)` | Write the dataframe to `path.csv` |\n",
    "| `df.to_parquet(path,index=False, engine='fastparquet')` | Write the dataframe to `path.parquet` |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
